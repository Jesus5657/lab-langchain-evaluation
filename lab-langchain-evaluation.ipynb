{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b00dae2-c271-4a69-a579-742e084a9058",
   "metadata": {
    "id": "1b00dae2-c271-4a69-a579-742e084a9058"
   },
   "source": [
    "# Lab | Langchain Evaluation\n",
    "\n",
    "## Intro\n",
    "\n",
    "Pick different sets of data and re-run this notebook. The point is for you to understand all steps involve and the many different ways one can and should evaluate LLM applications.\n",
    "\n",
    "What did you learn? - Let's discuss that in class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {
    "id": "52824b89-532a-4e54-87e9-1410813cd39e"
   },
   "source": [
    "## LangChain: Evaluation\n",
    "\n",
    "### Outline:\n",
    "\n",
    "* Example generation\n",
    "* Manual evaluation (and debuging)\n",
    "* LLM-assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sUC4CA0GmS6O",
   "metadata": {
    "id": "sUC4CA0GmS6O"
   },
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 98,
    "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Specify the exact path to your .env file in Google Drive\n",
    "#env_path = \"/content/drive/MyDrive/Ironhack/langchain_evaluation\"\n",
    "\n",
    "# Use find_dotenv() with the specified path\n",
    "#_ = load_dotenv(find_dotenv(env_path))\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4J8YqG8Ev6mo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4J8YqG8Ev6mo",
    "outputId": "bcfc8c5e-1568-4c1d-85b5-040912f610c6"
   },
   "outputs": [],
   "source": [
    "# Print statements to confirm API keys were loaded\n",
    "\n",
    "print(f\"OPENAI_API_KEY loaded: {bool(OPENAI_API_KEY)}\")\n",
    "print(f\"LANGCHAIN_API_KEY loaded: {bool(LANGCHAIN_API_KEY)}\")\n",
    "print(f\"HUGGINGFACEHUB_API_TOKEN loaded: {bool(HUGGINGFACEHUB_API_TOKEN)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j5-bl8RFwov4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5-bl8RFwov4",
    "outputId": "074283fd-f41a-4767-8be8-d5edaf47fcc0"
   },
   "outputs": [],
   "source": [
    "# Print statements to confirm API keys were loaded\n",
    "print(f\"OPENAI_API_KEY: {OPENAI_API_KEY}\")\n",
    "print(f\"LANGCHAIN_API_KEY: {LANGCHAIN_API_KEY}\")\n",
    "print(f\"HUGGINGFACEHUB_API_TOKEN: {HUGGINGFACEHUB_API_TOKEN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce74685f-50e9-48cf-8e2c-fac05e8e3ffd",
   "metadata": {
    "id": "ce74685f-50e9-48cf-8e2c-fac05e8e3ffd"
   },
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"]=\"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"]=LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"]=\"langchain_evaluation-IronHack_Lab\"\n",
    "os.environ[\"OPENAI_API_KEY\"]=OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e29d2c-ba67-4cba-8ded-375fe040b9ba",
   "metadata": {
    "id": "e7e29d2c-ba67-4cba-8ded-375fe040b9ba"
   },
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28008949",
   "metadata": {
    "id": "28008949"
   },
   "source": [
    "#### Create our QandA application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wy_dyiKym4dc",
   "metadata": {
    "id": "Wy_dyiKym4dc"
   },
   "outputs": [],
   "source": [
    "#!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PAxBgXWBnM58",
   "metadata": {
    "id": "PAxBgXWBnM58"
   },
   "outputs": [],
   "source": [
    "#!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E81y68C2nog2",
   "metadata": {
    "id": "E81y68C2nog2"
   },
   "outputs": [],
   "source": [
    "#!pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3s2HG8_Vs_uk",
   "metadata": {
    "id": "3s2HG8_Vs_uk"
   },
   "outputs": [],
   "source": [
    "#!pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 115,
    "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import CSVLoader, TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1106d",
   "metadata": {
    "height": 64,
    "id": "9ec1106d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = '/content/drive/MyDrive/Ironhack/langchain_evaluation/OutdoorClothingCatalog_1000.csv' #'../data/OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550eb642-c223-4d78-8f92-0f265ef78b86",
   "metadata": {
    "id": "550eb642-c223-4d78-8f92-0f265ef78b86",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade --force-reinstall sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bLOZ5seosna4",
   "metadata": {
    "id": "bLOZ5seosna4"
   },
   "outputs": [],
   "source": [
    "#!pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HvPN4EhWDGeU",
   "metadata": {
    "id": "HvPN4EhWDGeU"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade langchain pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c218f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 64,
    "id": "b31c218f",
    "outputId": "5c4e9177-5dee-44f8-ff83-87d98afd653a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\", model_kwargs = {'device': 'cuda'})\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2006054",
   "metadata": {
    "height": 183,
    "id": "a2006054",
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, api_key=OPENAI_API_KEY)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=index.vectorstore.as_retriever(),\n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ebd73",
   "metadata": {
    "id": "791ebd73"
   },
   "source": [
    "#### Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04a0f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "fb04a0f9",
    "outputId": "f5c709a1-52e7-469a-d27b-3f456e9f6926",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a88c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "fe4a88c2",
    "outputId": "a2d5f0c2-c8f9-4578-8d98-03c67f0f359e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d548aef",
   "metadata": {
    "id": "8d548aef"
   },
   "source": [
    "#### Hard-coded examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106fbd91-f7bc-4d6b-b090-54b6a485ce39",
   "metadata": {
    "id": "106fbd91-f7bc-4d6b-b090-54b6a485ce39",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d5af6-36db-4421-b635-46384e677847",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c5d5af6-36db-4421-b635-46384e677847",
    "outputId": "1680a07a-3ce2-486d-f548-e7c76ebb9ab1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Do the Cozy Comfort Pullover Set\\\n",
    "        have side pockets?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What collection is the Ultra-Lofty \\\n",
    "        850 Stretch Down Hooded Jacket from?\",\n",
    "        \"answer\": \"The DownTek collection\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"Examples:\\n\"\n",
    "             \"1. Query: Do the Cozy Comfort Pullover Set have side pockets?\\n\"\n",
    "             \"   Answer: Yes\\n\"\n",
    "             \"2. Query: What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?\\n\"\n",
    "             \"   Answer: The DownTek collection\\n\"\n",
    "             \"Query: {query}\\n\"\n",
    "             \"Answer:\"\n",
    ")\n",
    "\n",
    "# Define the output model\n",
    "class Answer(BaseModel):\n",
    "    answer: str = Field(description=\"The answer to the query\")\n",
    "\n",
    "# Create the output parser\n",
    "class AnswerOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> Answer:\n",
    "        # Split the response to get the answer\n",
    "        answer = text.strip().split(\"Answer:\")[-1].strip()\n",
    "        return Answer(answer=answer)\n",
    "\n",
    "# Initialize the LLM\n",
    "# llm = OpenAI()\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Create the LLMChain\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    output_parser=AnswerOutputParser()\n",
    ")\n",
    "\n",
    "# Example query\n",
    "query = \"Is the Cozy Comfort Pullover Set available in different colors?\"\n",
    "\n",
    "# Run the chain\n",
    "result = llm_chain.run({\"query\": query})\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coqJYsYZEtSf",
   "metadata": {
    "id": "coqJYsYZEtSf"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce3e4f",
   "metadata": {
    "id": "c7ce3e4f"
   },
   "source": [
    "#### LLM-Generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f8376",
   "metadata": {
    "height": 64,
    "id": "d44f8376",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e87816",
   "metadata": {
    "height": 47,
    "id": "34e87816",
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb34772-368f-4b5e-b4bd-da9b637cc7e8",
   "metadata": {
    "id": "acb34772-368f-4b5e-b4bd-da9b637cc7e8"
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abae09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 64,
    "id": "62abae09",
    "outputId": "3179fdff-0247-40cf-96fb-061faea040e9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ab28b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "97ab28b5",
    "outputId": "ce094f14-9c13-43fe-87c1-7b62fbff249f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe4228",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "0ebe4228",
    "outputId": "8f99f45b-5f95-460b-f74a-b20ec3426f7a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693fe86-feeb-4d73-b400-e66e79315274",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7693fe86-feeb-4d73-b400-e66e79315274",
    "outputId": "755af083-10b3-4af5-b55c-70429c0d8d34",
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_flattened = [data['qa_pairs'] for data in new_examples]\n",
    "d_flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf25f2f",
   "metadata": {
    "id": "faf25f2f"
   },
   "source": [
    "#### Combine examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2a3fc",
   "metadata": {
    "height": 30,
    "id": "ada2a3fc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# examples += new_example\n",
    "examples += d_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2184b9d7-22ab-43a5-9ba5-b27fef024874",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2184b9d7-22ab-43a5-9ba5-b27fef024874",
    "outputId": "7979fca6-53b2-455f-8926-de6ca1579c03",
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf5cf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "9cdf5cf5",
    "outputId": "34a85638-5099-4cbd-c087-c37d4f0d01af",
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa.invoke(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3cb08",
   "metadata": {
    "id": "63f3cb08"
   },
   "source": [
    "### Manual Evaluation - Fun part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf622e",
   "metadata": {
    "height": 47,
    "id": "fcaf622e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a142638",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "8a142638",
    "outputId": "efc4f9d8-826d-4d3c-e863-a94d522cf501",
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa.invoke(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d6bef0",
   "metadata": {
    "height": 47,
    "id": "b3d6bef0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn off the debug mode\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdbdce",
   "metadata": {
    "id": "d5bdbdce"
   },
   "source": [
    "### LLM assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54769b0-3daf-4cac-b259-89a10dd9b5a2",
   "metadata": {
    "id": "a54769b0-3daf-4cac-b259-89a10dd9b5a2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples += d_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea95385-1b4c-440a-9fea-8500b4cc2154",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ea95385-1b4c-440a-9fea-8500b4cc2154",
    "outputId": "41a0d00e-f463-428a-c529-7c6a84dfea0f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dca05a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "a4dca05a",
    "outputId": "8c95da18-2071-4c34-8a09-c23dfcc3c886",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = qa.batch(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e8b4e-4468-4048-8544-c9936704ea93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae7e8b4e-4468-4048-8544-c9936704ea93",
    "outputId": "7a4d3b21-6403-4980-bfc2-92e79f9e0fb2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012a3e0",
   "metadata": {
    "height": 30,
    "id": "6012a3e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b1c0b",
   "metadata": {
    "height": 47,
    "id": "724b1c0b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b46ae55",
   "metadata": {
    "height": 47,
    "id": "8b46ae55",
    "tags": []
   },
   "outputs": [],
   "source": [
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42eb35-c2d7-4581-8004-d315ade63eef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc42eb35-c2d7-4581-8004-d315ade63eef",
    "outputId": "9fda729a-3c41-42d4-fa23-c0f3116b2e1b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "graded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437cfbe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 149,
    "id": "3437cfbe",
    "outputId": "90e9b993-2975-4cc0-83d3-3d7c9aebd559",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    # print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721d127a-a9e3-465d-a8ae-0e2c4b4a2659",
   "metadata": {
    "id": "721d127a-a9e3-465d-a8ae-0e2c4b4a2659"
   },
   "source": [
    "### Example 2\n",
    "One can also easily evaluate your QA chains with the metrics offered in ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef0493-34ff-4801-b405-69c76ce86c38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5ef0493-34ff-4801-b405-69c76ce86c38",
    "outputId": "67554eb7-2daa-498f-8727-091b291d41b8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "loader = TextLoader(\"/content/drive/MyDrive/Ironhack/langchain_evaluation/nyc_text.txt\")\n",
    "index = VectorstoreIndexCreator(embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\", model_kwargs = {'device': 'cuda'})).from_loaders([loader])\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature= 0.0, api_key=OPENAI_API_KEY)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=index.vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0449cae-de25-4ef6-ae64-78ccf5e06a5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "f0449cae-de25-4ef6-ae64-78ccf5e06a5a",
    "outputId": "67cc1325-6f37-478c-d02c-29270b6a6b69",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing it out\n",
    "\n",
    "question = \"How did New York City get its name?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e846b3d-f79f-46eb-8075-c816268c0500",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e846b3d-f79f-46eb-8075-c816268c0500",
    "outputId": "08cd5f79-0bac-436c-e781-82e2a0b3f92b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d9da8-a593-4fc6-9d4b-fea2af6bdfd0",
   "metadata": {
    "id": "069d9da8-a593-4fc6-9d4b-fea2af6bdfd0"
   },
   "source": [
    "Now in order to evaluate the qa system we generated a few relevant questions. We've generated a few question for you but feel free to add any you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2cade-0005-41c1-b775-c6a7175bcf3b",
   "metadata": {
    "id": "a2e2cade-0005-41c1-b775-c6a7175bcf3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"What is the population of New York City as of 2020?\",\n",
    "    \"Which borough of New York City has the highest population?\",\n",
    "    \"What is the economic significance of New York City?\",\n",
    "    \"How did New York City get its name?\",\n",
    "    \"What is the significance of the Statue of Liberty in New York City?\",\n",
    "]\n",
    "\n",
    "eval_answers = [\n",
    "    \"8,804,190\",\n",
    "    \"Brooklyn\",\n",
    "    \"New York City's economic significance is vast, as it serves as the global financial capital, housing Wall Street and major financial institutions. Its diverse economy spans technology, media, healthcare, education, and more, making it resilient to economic fluctuations. NYC is a hub for international business, attracting global companies, and boasts a large, skilled labor force. Its real estate market, tourism, cultural industries, and educational institutions further fuel its economic prowess. The city's transportation network and global influence amplify its impact on the world stage, solidifying its status as a vital economic player and cultural epicenter.\",\n",
    "    \"New York City got its name when it came under British control in 1664. King Charles II of England granted the lands to his brother, the Duke of York, who named the city New York in his own honor.\",\n",
    "    \"The Statue of Liberty in New York City holds great significance as a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants who arrived in the U.S. by ship in the late 19th and early 20th centuries, representing hope and freedom for those seeking a better life. It has since become an iconic landmark and a global symbol of cultural diversity and freedom.\",\n",
    "]\n",
    "\n",
    "examples = [\n",
    "    {\"query\": q, \"ground_truths\": [eval_answers[i]]}\n",
    "    for i, q in enumerate(eval_questions)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac9358e-f8bc-4992-aea3-c83160ff0ab0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aac9358e-f8bc-4992-aea3-c83160ff0ab0",
    "outputId": "d46b694c-7d85-4ba6-f09e-b557cf2a1a86",
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21efe8-7c30-449a-9b8e-5b79778e305b",
   "metadata": {
    "id": "6a21efe8-7c30-449a-9b8e-5b79778e305b"
   },
   "source": [
    "#### Introducing RagasEvaluatorChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c2214-a6eb-4d4f-9403-7e1574b97a36",
   "metadata": {
    "id": "139c2214-a6eb-4d4f-9403-7e1574b97a36"
   },
   "source": [
    "`RagasEvaluatorChain` creates a wrapper around the metrics ragas provides (documented [here](https://github.com/explodinggradients/ragas/blob/main/docs/metrics.md)), making it easier to run these evaluation with langchain and langsmith.\n",
    "\n",
    "The evaluator chain has the following APIs\n",
    "\n",
    "- `__call__()`: call the `RagasEvaluatorChain` directly on the result of a QA chain.\n",
    "- `evaluate()`: evaluate on a list of examples (with the input queries) and predictions (outputs from the QA chain).\n",
    "- `evaluate_run()`: method implemented that is called by langsmith evaluators to evaluate langsmith datasets.\n",
    "\n",
    "lets see each of them in action to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c8aae-fe5f-4274-b638-9209151b9491",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "022c8aae-fe5f-4274-b638-9209151b9491",
    "outputId": "9b69afa2-10f0-4011-cc33-a209229fcb27",
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = qa_chain.invoke({\"query\": eval_questions[1]})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae31c80-42c9-4b1f-95b3-c05ceadb103f",
   "metadata": {
    "id": "eae31c80-42c9-4b1f-95b3-c05ceadb103f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_mapping = {\n",
    "    \"query\": \"question\",\n",
    "    \"result\": \"answer\",\n",
    "    \"source_documents\": \"contexts\"\n",
    "}\n",
    "\n",
    "result_updated = {}\n",
    "for old_key, new_key in key_mapping.items():\n",
    "    if old_key in result:\n",
    "        result_updated[new_key] = result[old_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4dd9f-16d7-43d4-ac8e-6c5aa5e3f7b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecd4dd9f-16d7-43d4-ac8e-6c5aa5e3f7b0",
    "outputId": "f628a612-5946-46ee-8879-a2278fceb154",
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d5cc30-d25e-41bd-8695-9246b73938bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00d5cc30-d25e-41bd-8695-9246b73938bc",
    "outputId": "8a781626-b78d-4ca6-e3f7-ed055b3a8e26",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install --no-cache-dir recordclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d55d9-437d-40c4-bb5f-87c7b65fa567",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "775d55d9-437d-40c4-bb5f-87c7b65fa567",
    "outputId": "8c1c1ec4-2fc3-4577-b084-5924d9f71bd8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install ragas==0.1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LuGtMnpKNc7p",
   "metadata": {
    "id": "LuGtMnpKNc7p"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b14c07-bf6c-4e86-ad1a-2a6c4d1a509d",
   "metadata": {
    "id": "29b14c07-bf6c-4e86-ad1a-2a6c4d1a509d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragas.integrations.langchain import EvaluatorChain\n",
    "# from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "# create evaluation chains\n",
    "faithfulness_chain   = EvaluatorChain(metric=faithfulness)\n",
    "answer_rel_chain     = EvaluatorChain(metric=answer_relevancy)\n",
    "context_rel_chain    = EvaluatorChain(metric=context_relevancy)\n",
    "context_recall_chain = EvaluatorChain(metric=context_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a8b636-d738-41bd-ac68-21cce2c4b720",
   "metadata": {
    "id": "41a8b636-d738-41bd-ac68-21cce2c4b720"
   },
   "source": [
    "1. `__call__()`\n",
    "\n",
    "Directly run the evaluation chain with the results from the QA chain. Do note that metrics like context_relevancy and faithfulness require the `source_documents` to be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815671c-1fc8-46ba-8356-4a0bd5558530",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7815671c-1fc8-46ba-8356-4a0bd5558530",
    "outputId": "2254db64-4921-4f72-bdae-d7112f6114a8"
   },
   "outputs": [],
   "source": [
    "# Recheck the result that we are going to validate.\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdd07c-956c-458f-8844-e056f29e3c83",
   "metadata": {
    "id": "8cfdd07c-956c-458f-8844-e056f29e3c83"
   },
   "source": [
    "**Faithfulness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SDzaxvtEOK0v",
   "metadata": {
    "id": "SDzaxvtEOK0v"
   },
   "outputs": [],
   "source": [
    "# Map keys as defined\n",
    "key_mapping = {\n",
    "    \"query\": \"question\",\n",
    "    \"result\": \"answer\",\n",
    "    \"source_documents\": \"contexts\"\n",
    "}\n",
    "\n",
    "result_updated = {}\n",
    "for old_key, new_key in key_mapping.items():\n",
    "    if old_key in result:\n",
    "        if old_key == \"source_documents\":  # Handle contexts specifically\n",
    "            # Extract 'page_content' from each Document and ensure all are strings\n",
    "            list_context = [doc.page_content for doc in result[old_key]]\n",
    "            result_updated[new_key] = ' '.join(list_context)\n",
    "\n",
    "        else:\n",
    "            result_updated[new_key] = result[old_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vw460FfNT-24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vw460FfNT-24",
    "outputId": "d940cd48-b1fd-4061-863c-c39446b45078"
   },
   "outputs": [],
   "source": [
    "result_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ATZYmR7SUH5n",
   "metadata": {
    "id": "ATZYmR7SUH5n"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y4VpSNXyV-8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4VpSNXyV-8b",
    "outputId": "24584dad-3c4e-4a6d-bba7-ffd7b1e45e16"
   },
   "outputs": [],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f5f0f-a237-4584-becb-a35607caf26b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "304f5f0f-a237-4584-becb-a35607caf26b",
    "outputId": "d0d44bfc-c64d-46ae-9d99-a714f9ba8b8f"
   },
   "outputs": [],
   "source": [
    "eval_result = faithfulness_chain(result_updated)\n",
    "eval_result[\"faithfulness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd78a9-d7c5-42a0-8705-4c544ec6408e",
   "metadata": {
    "id": "8fbd78a9-d7c5-42a0-8705-4c544ec6408e"
   },
   "source": [
    "High faithfulness_score means that there are exact consistency between the source documents and the answer.\n",
    "\n",
    "You can check lower faithfulness scores by changing the result (answer from LLM) or source_documents to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MooyRz2pZzpR",
   "metadata": {
    "id": "MooyRz2pZzpR"
   },
   "outputs": [],
   "source": [
    "# Map keys as defined\n",
    "key_mapping = {\n",
    "    \"query\": \"question\",\n",
    "    \"result\": \"answer\",\n",
    "    \"source_documents\": \"contexts\"\n",
    "}\n",
    "\n",
    "fake_result = {}\n",
    "for old_key, new_key in key_mapping.items():\n",
    "    if old_key in result:\n",
    "        if old_key == \"source_documents\":  # Handle contexts specifically\n",
    "            # Extract 'page_content' from each Document and ensure all are strings\n",
    "            list_context = [doc.page_content for doc in result[old_key]]\n",
    "            fake_result[new_key] = ' '.join(list_context)\n",
    "\n",
    "        else:\n",
    "            fake_result[new_key] = result[old_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D8cIjD_oaH3P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8cIjD_oaH3P",
    "outputId": "b166bbb1-c0b7-4be0-a4af-61398396405d"
   },
   "outputs": [],
   "source": [
    "fake_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t-jii2Ihai6o",
   "metadata": {
    "id": "t-jii2Ihai6o"
   },
   "outputs": [],
   "source": [
    "fake_result[\"answer\"] = \"we are the champions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GL3gCrCfamvj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GL3gCrCfamvj",
    "outputId": "e13728e4-d0f4-4d29-9749-bfadbb4d3f35"
   },
   "outputs": [],
   "source": [
    "fake_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f42b97-a84f-4015-9da5-fa3b0b703c24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15f42b97-a84f-4015-9da5-fa3b0b703c24",
    "outputId": "2f1042c1-aa03-4d76-f202-67618f1ad974"
   },
   "outputs": [],
   "source": [
    "#fake_result = result.copy()\n",
    "#fake_result[\"answer\"] = \"we are the champions\"\n",
    "eval_result = faithfulness_chain(fake_result)\n",
    "eval_result[\"faithfulness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UF3PYXprb9H6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UF3PYXprb9H6",
    "outputId": "114ef9f3-23df-4b1c-8196-f277a367a21c"
   },
   "outputs": [],
   "source": [
    "fake_result_2 = fake_result.copy()\n",
    "fake_result_2[\"answer\"] = \"Brooklyn is the biggest borough of NY\"\n",
    "eval_result = faithfulness_chain(fake_result_2)\n",
    "eval_result[\"faithfulness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i3oI6Z14cfZq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3oI6Z14cfZq",
    "outputId": "d614089f-cdcd-497f-ad5b-f0179802819f"
   },
   "outputs": [],
   "source": [
    "fake_result_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02348380-159a-4578-a95e-493cdcfcebe7",
   "metadata": {
    "id": "02348380-159a-4578-a95e-493cdcfcebe7"
   },
   "source": [
    "**Context Relevancy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TkLOptNBiU7W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkLOptNBiU7W",
    "outputId": "031a529f-a2a2-4332-95a5-f26ac70921ac"
   },
   "outputs": [],
   "source": [
    "# Rename 'answer' key to 'ground_truth'\n",
    "result_updated_gt={}\n",
    "result_updated_gt=result_updated.copy() # Create a copy to avoid modifying the original dictionary\n",
    "result_updated_gt[\"ground_truth\"] = result_updated.pop(\"answer\") # Assign the value of the key 'answer' to new key named 'ground_truth'\n",
    "\n",
    "# Verify the updated result structure\n",
    "print(result_updated_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2fb9e-19d1-4cf6-9773-897546c2d6bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fd2fb9e-19d1-4cf6-9773-897546c2d6bb",
    "outputId": "6be47dcf-7af7-44c4-aed2-0e444a76087a"
   },
   "outputs": [],
   "source": [
    "eval_result = context_recall_chain(result_updated_gt)\n",
    "eval_result[\"context_recall\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118cba80-c2a3-408e-9d8d-857521cbe723",
   "metadata": {
    "id": "118cba80-c2a3-408e-9d8d-857521cbe723"
   },
   "source": [
    "High context_recall_score means that the ground truth is present in the source documents.\n",
    "\n",
    "You can check lower context recall scores by changing the source_documents to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-nd5juBylCVH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nd5juBylCVH",
    "outputId": "d71a865f-5fa5-4fe0-9ef4-b2c7b9e87f49"
   },
   "outputs": [],
   "source": [
    "fake_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p86BzzEbnFYz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p86BzzEbnFYz",
    "outputId": "f46a2f85-4994-42ac-ec36-c548db9edc08"
   },
   "outputs": [],
   "source": [
    "# Create a new fake_result_03 based on the current fake_result structure\n",
    "fake_result_03 = fake_result.copy()  # Start with a copy of fake_result\n",
    "\n",
    "# Update the answer to the correct response\n",
    "fake_result_03[\"answer\"] = \"Manhattan (New York County) has the highest population density of any borough in New York City.\"\n",
    "\n",
    "# Add the ground_truth key with the correct response\n",
    "fake_result_03[\"ground_truth\"] = \"Manhattan (New York County) has the highest population density of any borough in New York City.\"\n",
    "\n",
    "# Modify contexts to be a single irrelevant string\n",
    "fake_result_03[\"contexts\"] = \"I love christmas\"\n",
    "\n",
    "# Print the updated fake_result_03 for verification\n",
    "print(fake_result_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6610c5f-5f8e-406c-885c-093012a5dc44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6610c5f-5f8e-406c-885c-093012a5dc44",
    "outputId": "d37a4af6-6a44-4dd1-a7db-a411c550e43a"
   },
   "outputs": [],
   "source": [
    "#from langchain.schema import Document\n",
    "#fake_result = result.copy()\n",
    "#fake_result[\"source_documents\"] = [Document(page_content=\"I love christmas\")]\n",
    "eval_result = context_recall_chain(fake_result_03)\n",
    "eval_result[\"context_recall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nSWWM6lfqrRF",
   "metadata": {
    "id": "nSWWM6lfqrRF"
   },
   "outputs": [],
   "source": [
    "fake_result_04 = fake_result_03.copy()\n",
    "fake_result_04[\"contexts\"] = (\n",
    "    \"New York City has a large population, and Manhattan is one of its boroughs. \"\n",
    "    \"However, Brooklyn also has a significant population density.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9gTYAidFrNh6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gTYAidFrNh6",
    "outputId": "bc9f99fe-3b88-4595-a385-989b5e5e5ac0"
   },
   "outputs": [],
   "source": [
    "fake_result_04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6s4zVL_krKUA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6s4zVL_krKUA",
    "outputId": "1ff03fe6-3460-42af-c4a2-89ca7ea2a9a3"
   },
   "outputs": [],
   "source": [
    "eval_result = context_recall_chain(fake_result_04)\n",
    "eval_result[\"context_recall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uZgjdGvDr8lg",
   "metadata": {
    "id": "uZgjdGvDr8lg"
   },
   "outputs": [],
   "source": [
    "fake_result_05 = fake_result_04.copy()\n",
    "fake_result_05[\"contexts\"] = (\n",
    "    \"Manhattan has a high population density. \"\n",
    "    \"Brooklyn also has a significant population density, but Manhattan's is higher.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cI0yDLiHr8Zp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cI0yDLiHr8Zp",
    "outputId": "b27615bd-ed22-4a15-836a-05cb60fe0fd1"
   },
   "outputs": [],
   "source": [
    "fake_result_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uT-xSU8Nr8MX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uT-xSU8Nr8MX",
    "outputId": "337444cb-5e59-4a30-e2bd-42628a5cb5b9"
   },
   "outputs": [],
   "source": [
    "eval_result = context_recall_chain(fake_result_05)\n",
    "eval_result[\"context_recall\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc06403-c514-47fd-ac82-d95ece8d2f06",
   "metadata": {
    "id": "3dc06403-c514-47fd-ac82-d95ece8d2f06"
   },
   "source": [
    "2. `evaluate()`\n",
    "\n",
    "Evaluate a list of inputs/queries and the outputs/predictions from the QA chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4UzEdeK1tv3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UzEdeK1tv3f",
    "outputId": "7b60678f-4615-400e-ff96-0afcf96b00fd"
   },
   "outputs": [],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V_zyOLgGtxzy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_zyOLgGtxzy",
    "outputId": "674abb58-93cc-42f6-865f-46a03f645959"
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qKAI-razxWek",
   "metadata": {
    "id": "qKAI-razxWek"
   },
   "outputs": [],
   "source": [
    "# run the queries as a batch for efficiency\n",
    "predictions = qa_chain.batch(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qZgTE3_3zXTQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZgTE3_3zXTQ",
    "outputId": "e735da0f-5d5e-493a-80e3-9686668dc936"
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ktr6LDWwZB0",
   "metadata": {
    "id": "1ktr6LDWwZB0"
   },
   "outputs": [],
   "source": [
    "# Map keys as defined\n",
    "key_mapping_p = {\n",
    "    \"query\": \"question\",\n",
    "    \"ground_truths\": \"ground_truth\",\n",
    "    \"result\": \"answer\",\n",
    "    \"source_documents\": \"contexts\"\n",
    "}\n",
    "\n",
    "formatted_predictions = {}\n",
    "for old_key, new_key in key_mapping_p.items():\n",
    "    if old_key in predictions:\n",
    "        if old_key == \"source_documents\":  # Handle contexts specifically\n",
    "            # Extract 'page_content' from each Document and ensure all are strings\n",
    "            list_context = [doc.page_content for doc in predictions[old_key]]\n",
    "            formatted_predictions[new_key] = ' '.join(list_context)\n",
    "\n",
    "        else:\n",
    "            formatted_predictions[new_key] = predictions[old_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zzBpTz3U0wqm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzBpTz3U0wqm",
    "outputId": "a174bfa3-36a0-4df9-81bc-70f531babb9d"
   },
   "outputs": [],
   "source": [
    "# Define the key mapping\n",
    "key_mapping_p = {\n",
    "    \"query\": \"question\",\n",
    "    \"ground_truths\": \"ground_truth\",\n",
    "    \"result\": \"answer\",\n",
    "    \"source_documents\": \"contexts\",\n",
    "}\n",
    "\n",
    "# Initialize the list to store formatted predictions\n",
    "formatted_predictions = []\n",
    "\n",
    "# Iterate over each prediction in the list\n",
    "for prediction in predictions:\n",
    "    formatted_prediction = {}\n",
    "    for old_key, new_key in key_mapping_p.items():\n",
    "        if old_key == \"source_documents\":\n",
    "            # Handle 'source_documents' specifically\n",
    "            list_context = [doc.page_content for doc in prediction.get(old_key, [])]\n",
    "            formatted_prediction[new_key] = \" \".join(list_context)\n",
    "        else:\n",
    "            # Map other keys directly\n",
    "            formatted_prediction[new_key] = prediction.get(old_key)\n",
    "    formatted_predictions.append(formatted_prediction)\n",
    "\n",
    "# Print the formatted predictions\n",
    "formatted_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b23708-b94d-4649-acd9-0e268f72f94a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6b23708-b94d-4649-acd9-0e268f72f94a",
    "outputId": "1d53a361-51a6-4367-92f0-46fb86055de1"
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "print(\"evaluating...\")\n",
    "#r = faithfulness_chain.evaluate(examples, predictions)\n",
    "r = await faithfulness_chain.abatch(formatted_predictions)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d661f6b9-04c7-40b7-874b-25f53cfab9d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d661f6b9-04c7-40b7-874b-25f53cfab9d9",
    "outputId": "c924e45d-ad6d-42cb-b57f-2cd878d22ae6"
   },
   "outputs": [],
   "source": [
    "# evaluate context recall\n",
    "print(\"evaluating...\")\n",
    "cr = await context_recall_chain.abatch(formatted_predictions)\n",
    "cr"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
